// Create file: src/tools.ts
import { z } from 'zod';
import _ from 'lodash';
import { Database } from 'bun:sqlite';
import vm from 'vm';

import { ClientFullEHR } from '../clientTypes.js'; // Import using relative path

// --- Configuration ---
const MAX_GREP_JSON_LENGTH = 2 * 1024 * 1024; // 2 MB limit
const MAX_QUERY_JSON_LENGTH = 500 * 1024;      // 500 KB limit
const MAX_EVAL_JSON_LENGTH = 1 * 1024 * 1024;  // 1 MB limit
const MAX_QUERY_ROWS = 500; // Limit rows for query results before stringification check

// --- Tool Schemas ---

export const GrepRecordInputSchema = z.object({
    query: z.string().min(1).describe("The text string or JavaScript-style regular expression to search for (case-insensitive). Example: 'heart attack|myocardial infarction|mi'"),
    resource_types: z.array(z.string()).optional().describe(
        `Optional list to filter the search scope. Supports FHIR resource type names (e.g., "Patient", "Observation") and the special keyword "Attachment".
        Behavior based on the list:
        - **If omitted or an empty list is provided:** Searches EVERYTHING - all FHIR resources and all attachment plaintext.
        - **List contains only FHIR types (e.g., ["Condition", "Procedure"]):** Searches ONLY the specified FHIR resource types AND the plaintext of attachments belonging *only* to those specified resource types.
        - **List contains only ["Attachment"]:** Searches ONLY the plaintext content of ALL attachments, regardless of which resource they belong to.
        - **List contains FHIR types AND "Attachment" (e.g., ["DocumentReference", "Attachment"]):** Searches the specified FHIR resource types (e.g., DocumentReference) AND the plaintext of ALL attachments (including those not belonging to the specified FHIR types).`
    )
});

export const GrepMatchedAttachmentSchema = z.object({
    resourceType: z.string().describe("The FHIR resource type the attachment belongs to."),
    resourceId: z.string().describe("The ID of the FHIR resource the attachment belongs to."),
    path: z.string().describe("Path within the original resource where the attachment was found (e.g., 'content.attachment')."),
    contentType: z.string().optional().describe("The content type of the attachment."),
    plaintext: z.string().describe("The full extracted plaintext content of the attachment.")
}).describe("An attachment where the query matched within its extracted plaintext content.");


export const GrepRecordOutputSchema = z.object({
    warning: z.string().optional().describe("Warning message if results were truncated."),
    matched_resources: z.array(z.record(z.unknown())).describe("Full FHIR resources where the query matched anywhere within their JSON representation."),
    matched_attachments: z.array(GrepMatchedAttachmentSchema).describe("Attachments where the query matched within their extracted plaintext content."),
    resources_searched_count: z.number().int().describe("Number of FHIR resources searched."),
    attachments_searched_count: z.number().int().describe("Number of attachments searched."),
    resources_matched_count: z.number().int().describe("Number of unique FHIR resources matched."),
    attachments_matched_count: z.number().int().describe("Number of unique attachments matched."),
    error: z.string().optional().describe("Error message if truncation failed or result is still too large.")
}).describe("Results of the text search across the patient's record using a case-insensitive string or JavaScript-style regular expression, returning full matching resources or attachment text.");


export const QueryRecordInputSchema = z.object({
    sql: z.string().min(1).describe("The read-only SQL SELECT statement to execute against the in-memory FHIR data. FHIR resources are stored in the 'fhir_resources' table with columns 'resource_type', 'resource_id', and 'json'. For example, 'SELECT json FROM fhir_resources WHERE resource_type = \"Patient\"' or 'SELECT json FROM fhir_resources WHERE resource_type = \"Observation\" AND json LIKE \"%diabetes%\"'.")
});
export const QueryRecordOutputSchema = z.union([
    z.array(z.record(z.unknown())).describe("An array of rows returned by the SQL query. Each row is an object where keys are column names."),
    z.object({
        warning: z.string().optional(),
        error: z.string().optional(),
        truncated_results: z.array(z.record(z.unknown())).optional()
    }).describe("Object indicating truncated results or an error during processing/truncation.")
]);

// TODO: Define AskQuestion schemas if this tool is re-enabled
// export const AskQuestionInputSchema = z.object({
//     question: z.string().min(1).describe("The natural language question to ask about the patient's record.")
// });
// export const AskQuestionOutputSchema = z.object({ answer: z.string() }).describe("The natural language answer generated by the LLM based on the record context."); // Simple wrapper for now

// TODO: Define ResyncRecord schemas if this tool is re-enabled
// export const ResyncRecordInputSchema = z.object({}).describe("No arguments needed.");
// export const ResyncRecordOutputSchema = z.object({ message: z.string() }).describe("A confirmation message indicating the outcome of the resync attempt.");


export const EvalRecordInputSchema = z.object({
    code: z.string().min(1).describe(
        `A string containing the body of an async JavaScript function.
        This function receives the following arguments:
        1. 'fullEhr': An object containing the patient's EHR data (ClientFullEHR format):
           - 'fullEhr.fhir': An object where keys are FHIR resource type strings (e.g., "Patient", "Observation") and values are arrays of the corresponding FHIR resource JSON objects.
           - 'fullEhr.attachments': An array of processed attachment objects (ClientProcessedAttachment format from 'clientTypes.ts'). Each object includes:
             - 'resourceType', 'resourceId', 'path', 'contentType'
             - 'contentPlaintext': The extracted plaintext content (string or null).
             - 'contentBase64': Raw content encoded as a base64 string (string or null).
             - 'json': The original JSON string of the attachment node.
        2. 'console': A limited console object with 'log', 'warn', and 'error' methods that capture output.
        3. '_': The Lodash library (v4). Useful for data manipulation (e.g., _.find, _.map, _.filter).
        4. 'Buffer': The Node.js Buffer class. Useful for operations like base64 decoding (e.g., Buffer.from(base64String, 'base64').toString('utf8')).

        The function MUST conclude with a 'return' statement specifying the JSON-serializable value to send back.
        Do NOT define the function signature ('async function(...) { ... }') within the code string, only provide the body.
        Console output will be captured separately and returned alongside the function's result or any execution errors.

        Example Input (Note: Access .contentBase64 for binary, .contentPlaintext for text):
        {
          "code": "const conditions = fullEhr.fhir['Condition'] || [];\\nconst activeProblems = conditions.filter(c => c.clinicalStatus?.coding?.[0]?.code === 'active');\\nconst diabeteConditions = activeProblems.filter(c => JSON.stringify(c.code).toLowerCase().includes('diabete'));\\n\\n// Get patient name (handle potential missing data)\\nconst patient = (fullEhr.fhir['Patient'] || [])[0];\\nlet patientName = 'Unknown';\\nif (patient && patient.name && patient.name[0]) {\\n  patientName = \`\${patient.name[0].given?.join(' ') || ''} \${patient.name[0].family || ''}\`.trim();\\n}\\n\\nconsole.log(\`Found \${diabeteConditions.length} active diabetes condition(s) for patient \${patientName}.\`);\\n\\n// Find PDF attachments\\nconst pdfAttachments = fullEhr.attachments.filter(a => a.contentType === 'application/pdf');\\nconsole.warn(\`Found \${pdfAttachments.length} PDF attachments.\`);\\n\\n// Example of decoding base64 (if needed, check contentPlaintext first!)\\nconst firstAttachment = fullEhr.attachments[0];\\nif (firstAttachment && firstAttachment.contentBase64) {\\n try {\\n   // Only decode if contentPlaintext wasn't useful\\n   // const decodedText = Buffer.from(firstAttachment.contentBase64, 'base64').toString('utf8');\\n   // console.log('Decoded snippet:', decodedText.substring(0, 50));\\n } catch (e) { console.error('Error decoding base64 for first attachment'); }\\n}\\n\\nreturn { \\n  patient: patientName,\\n  activeDiabetesCount: diabeteConditions.length,\\n  diabetesDetails: diabeteConditions.map(c => ({ id: c.id, code: c.code?.text || JSON.stringify(c.code), onset: c.onsetDateTime || c.onsetAge?.value }))\\n};"
        }`
    )
});


export const EvalRecordOutputSchema = z.object({
    result: z.any().optional().describe("The JSON-serializable result returned by the executed code (if successful). Will be 'undefined' if the code threw an error or did not return a value. Can be '[Result omitted due to excessive size]' if truncated."),
    logs: z.array(z.string()).describe("An array of messages logged via console.log or console.warn during execution. Can contain truncation messages."),
    errors: z.array(z.string()).describe("An array of messages logged via console.error during execution, or internal execution errors (like timeouts or syntax errors). Can contain truncation messages.")
}).describe("The result of executing the provided JavaScript code against the patient record, including the returned value and captured console output/errors.");


// --- Logic Functions ---

/**
 * Truncates a data object (intended for JSON stringification) if its stringified
 * representation exceeds a specified limit. Applies tool-specific truncation logic.
 *
 * @param data The data object to potentially truncate.
 * @param limit The maximum allowed length of the JSON string.
 * @param toolType Identifier for the tool to apply specific logic ('grep', 'query', 'eval').
 * @returns The potentially modified data object, ready for stringification.
 */
function truncateIfNeeded(data: any, limit: number, toolType: 'grep' | 'query' | 'eval'): any {
    try {
        let jsonString = JSON.stringify(data); // Initial stringification (potentially large)
        if (jsonString.length <= limit) {
            return data; // No truncation needed
        }

        console.warn(`[TRUNCATE ${toolType.toUpperCase()}] Result exceeds limit (${(jsonString.length / 1024).toFixed(0)} KB > ${(limit / 1024).toFixed(0)} KB), applying truncation.`);

        let truncatedData: any;
        let warningMessage = `Result truncated due to size limit (${(limit / 1024).toFixed(0)} KB).`;

        switch (toolType) {
            case 'grep':
                truncatedData = {
                    ...data, // Copy counts etc.
                    matched_resources: data.matched_resources.slice(0, 5), // Limit resources
                    matched_attachments: data.matched_attachments.slice(0, 10)?.map((att: any) => ({ // Limit attachments & plaintext
                        ...att,
                        plaintext: att.plaintext.length > 500 ? att.plaintext.substring(0, 500) + "..." : att.plaintext
                    }))
                };
                warningMessage += " Showing subset of matches. Attachment plaintext may be shortened.";
                break;

            case 'query':
                // Assumes 'data' is the array of results here
                const originalRowCount = data.length;
                const truncatedRows = data.slice(0, MAX_QUERY_ROWS); // Use row limit first
                truncatedData = { // Return structure with warning
                    warning: `Result truncated. Showing first ${truncatedRows.length} of ${originalRowCount} rows.`,
                    truncated_results: truncatedRows
                };
                warningMessage = truncatedData.warning; // Use specific row count warning
                break;

            case 'eval':
                // Prioritize errors > logs > result
                 const originalLogs = data.logs || [];
                 const originalErrors = data.errors || [];
                truncatedData = {
                    result: "[Result omitted due to excessive size]",
                    logs: originalLogs.slice(0, 20),
                    errors: [...originalErrors] // Copy original errors
                };
                 warningMessage += " Result omitted, logs potentially truncated.";
                 if (truncatedData.logs.length < originalLogs.length) {
                    truncatedData.logs.push("... [Logs truncated due to size limit]");
                }
                 // Add the primary warning to the errors array as well
                 truncatedData.errors.push(`Execution result (or combined output) was too large to return fully. ${warningMessage}`);
                break;

            default:
                console.error(`[TRUNCATE] Unknown toolType: ${toolType}`);
                return { error: `Internal error: Unknown tool type for truncation.` }; // Should not happen
        }

        // Add the warning to the truncated data structure if a field exists
        if (typeof truncatedData === 'object' && truncatedData !== null) {
             truncatedData.warning = warningMessage;
        }

        // Final check: Stringify the *truncated* data and see if it's STILL too large
        let finalJsonString = JSON.stringify(truncatedData);
        if (finalJsonString.length > limit) {
            console.error(`[TRUNCATE ${toolType.toUpperCase()}] Result STILL too large after truncation.`);
            // Return a minimal error object for each tool type
            switch (toolType) {
                case 'grep': return { error: "Result too large to return, even after truncation.", resources_searched_count: data.resources_searched_count, attachments_searched_count: data.attachments_searched_count, resources_matched_count: data.resources_matched_count, attachments_matched_count: data.attachments_matched_count };
                case 'query': return { error: "Result too large to return, even after truncation." };
                case 'eval': return { error: "Result too large to return, even after truncation.", logs: [], result: undefined, errors: ["Output exceeded size limit even after truncation."] };
                default: return { error: "Result too large to return, even after truncation." };
            }
        }

        return truncatedData; // Return the successfully truncated data object

    } catch (stringifyError: any) {
        console.error(`[TRUNCATE ${toolType.toUpperCase()}] Error during stringification/truncation:`, stringifyError);
        return { error: `Internal error during result processing/truncation: ${stringifyError.message}` };
    }
}


export async function grepRecordLogic(
    fullEhr: ClientFullEHR,
    query: string,
    inputResourceTypes?: string[]
): Promise<string> { // Returns JSON string
    let regex: RegExp;
    try {
        if (query.startsWith('/') && query.endsWith('/')) query = query.slice(1, -1);
        regex = new RegExp(query, 'i');
        console.error(`[GREP Logic] Using regex: ${regex}`);
    } catch (e) {
        console.error(`[GREP Logic] Invalid regex: "${query}"`, e);
        const errorResult = { error: `Invalid regular expression provided: ${query}. Ensure special characters are properly escaped if needed.` };
        return JSON.stringify(errorResult, null, 2);
    }

    const matchedResourceIds = new Set<string>();
    const matchedAttachmentKeys = new Set<string>();
    const matchedResourcesResult: Record<string, unknown>[] = [];
    const matchedAttachmentsResult: z.infer<typeof GrepMatchedAttachmentSchema>[] = [];
    let resourcesSearched = 0;
    let attachmentsSearched = 0;

    const searchOnlyAttachments = inputResourceTypes?.length === 1 && inputResourceTypes[0] === "Attachment";
    let typesForResourceSearch: string[] = [];
    let typesForAttachmentFilter: string[] | null = null;

    if (searchOnlyAttachments) {
        typesForResourceSearch = [];
        typesForAttachmentFilter = null;
        console.error("[GREP Logic] Scope: Attachments Only");
    } else if (!inputResourceTypes || inputResourceTypes.length === 0) {
        typesForResourceSearch = Object.keys(fullEhr.fhir);
        typesForAttachmentFilter = null;
        console.error("[GREP Logic] Scope: All Resources and All Attachments (Default)");
    } else {
        typesForResourceSearch = inputResourceTypes.filter(t => t !== "Attachment");
        if (inputResourceTypes.includes("Attachment")) {
            typesForAttachmentFilter = null;
             console.error(`[GREP Logic] Scope: Resources [${typesForResourceSearch.join(', ')}] and ALL Attachments`);
        } else {
            typesForAttachmentFilter = typesForResourceSearch;
             console.error(`[GREP Logic] Scope: Resources [${typesForResourceSearch.join(', ')}] and their specific Attachments`);
        }
    }

    // 1. Search FHIR Resources
     if (typesForResourceSearch.length > 0) {
         console.error(`[GREP Logic] Searching ${typesForResourceSearch.length} resource types...`);
         for (const resourceType of typesForResourceSearch) {
             const resources = fullEhr.fhir[resourceType] || [];
             for (const resource of resources) {
                if (!resource || typeof resource !== 'object' || !resource.resourceType || !resource.id) {
                     console.warn(`[GREP Logic] Skipping invalid resource structure in type '${resourceType}'.`); continue;
                 }
                resourcesSearched++;
                const resourceKey = `${resource.resourceType}/${resource.id}`;
                if (matchedResourceIds.has(resourceKey)) continue;
                try {
                    if (regex.test(JSON.stringify(resource))) {
                        matchedResourceIds.add(resourceKey);
                        matchedResourcesResult.push(resource);
                    }
                } catch (stringifyError) {
                    console.warn(`[GREP Logic] Error stringifying resource ${resourceKey}:`, stringifyError);
                 }
             }
         }
         console.error(`[GREP Logic] Found ${matchedResourcesResult.length} matching resources after searching ${resourcesSearched}.`);
     } else {
         console.error("[GREP Logic] Skipping resource search based on scope.");
     }

    // 2. Search Attachments
     console.error(`[GREP Logic] Searching ${fullEhr.attachments.length} attachments (Filter: ${typesForAttachmentFilter ? `Only types [${typesForAttachmentFilter.join(', ')}]` : 'All'})...`);
     for (const attachment of fullEhr.attachments) {
        if (!attachment || !attachment.resourceType || !attachment.resourceId || !attachment.path) {
             console.warn(`[GREP Logic] Skipping invalid attachment structure.`); continue;
         }
        attachmentsSearched++;
        const attachmentKey = `${attachment.resourceType}/${attachment.resourceId}#${attachment.path}`;
        if (typesForAttachmentFilter && !typesForAttachmentFilter.includes(attachment.resourceType)) continue;
        if (matchedAttachmentKeys.has(attachmentKey)) continue;

        if (attachment.contentPlaintext && typeof attachment.contentPlaintext === 'string' && attachment.contentPlaintext.length > 0) {
            if (regex.test(attachment.contentPlaintext)) {
                matchedAttachmentKeys.add(attachmentKey);
                matchedAttachmentsResult.push({
                    resourceType: attachment.resourceType,
                    resourceId: attachment.resourceId,
                    path: attachment.path,
                    contentType: attachment.contentType,
                    plaintext: attachment.contentPlaintext
                });
            }
        }
     }
     console.error(`[GREP Logic] Found ${matchedAttachmentsResult.length} matching attachments after searching ${attachmentsSearched}.`);


    // 3. Compile results and truncate if needed
    const resultData: z.infer<typeof GrepRecordOutputSchema> = {
        matched_resources: matchedResourcesResult,
        matched_attachments: matchedAttachmentsResult,
        resources_searched_count: resourcesSearched,
        attachments_searched_count: attachmentsSearched,
        resources_matched_count: matchedResourcesResult.length,
        attachments_matched_count: matchedAttachmentsResult.length,
    };

    const finalData = truncateIfNeeded(resultData, MAX_GREP_JSON_LENGTH, 'grep');
    return JSON.stringify(finalData, null, 2);
}


export async function queryRecordLogic(db: Database, sql: string): Promise<string> { // Returns JSON string
    console.error(`[SQL Logic] Executing query: ${sql.substring(0, 100)}${sql.length > 100 ? '...' : ''}`);

    // Basic validation to prevent modifications
    const sqlLower = sql.trim().toLowerCase();
    if (!sqlLower.startsWith('select')) {
        console.error("[SQL Logic] Validation failed: Query does not start with SELECT.");
        const errorResult = { error: "Only SELECT queries are allowed." };
        return JSON.stringify(errorResult, null, 2);
    }
    const writeKeywords = ['insert ', 'update ', 'delete ', 'drop ', 'create ', 'alter ', 'attach ', 'detach ', 'replace ', 'pragma '];
     if (writeKeywords.some(keyword => sqlLower.includes(keyword))) {
         if (!sqlLower.startsWith('pragma table_info') && !sqlLower.startsWith('pragma user_version')) {
            console.error(`[SQL Logic] Validation failed: Potentially harmful SQL keyword detected.`);
            const errorResult = { error: "Potentially harmful SQL operation detected. Only SELECT statements and specific PRAGMAs are permitted." };
            return JSON.stringify(errorResult, null, 2);
        }
     }

    try {
        const results = await db.query(sql).all() as Record<string, unknown>[];
        console.error(`[SQL Logic] Query returned ${results.length} rows.`);

        // Truncate if needed
        const finalData = truncateIfNeeded(results, MAX_QUERY_JSON_LENGTH, 'query');
        return JSON.stringify(finalData, null, 2);

    } catch (err: any) {
        console.error("[SQL Logic] Query execution error:", err);
        const errorResult = { error: `SQL execution failed: ${err.message}` };
        return JSON.stringify(errorResult, null, 2);
    }
}

export async function evalRecordLogic(
    fullEhr: ClientFullEHR,
    userCode: string
): Promise<string> { // Returns JSON string
    const logs: string[] = [];
    const errors: string[] = [];
    const MAX_LOG_MESSAGES = 100;

    console.error(`[EVAL Logic] Preparing to execute sandboxed code...`);

    const sandboxConsole = {
        log: (...args: any[]) => { if (logs.length < MAX_LOG_MESSAGES) logs.push(args.map(arg => typeof arg === 'string' ? arg : JSON.stringify(arg)).join(' ')); else if (logs.length === MAX_LOG_MESSAGES) logs.push("... [Max log messages reached]"); },
        warn: (...args: any[]) => { if (logs.length < MAX_LOG_MESSAGES) logs.push(`WARN: ${args.map(arg => typeof arg === 'string' ? arg : JSON.stringify(arg)).join(' ')}`); else if (logs.length === MAX_LOG_MESSAGES) logs.push("... [Max log messages reached]"); },
        error: (...args: any[]) => errors.push(`CONSOLE.ERROR: ${args.map(arg => typeof arg === 'string' ? arg : JSON.stringify(arg)).join(' ')}`),
    };

    const sandbox = { fullEhr, console: sandboxConsole, _: _, Buffer: Buffer, __resultPromise__: undefined as Promise<any> | undefined };
    const scriptCode = `async function userFunction(fullEhr, console, _, Buffer) { "use strict"; ${userCode} }\n__resultPromise__ = userFunction(fullEhr, console, _, Buffer);`;
    const context = vm.createContext(sandbox);
    const script = new vm.Script(scriptCode, { filename: 'userCode.vm' });
    const timeoutMs = 5000;
    let executionResult: any = undefined;
    let executionError: Error | null = null;

    try {
        console.error(`[EVAL Logic] Executing sandboxed code (Timeout: ${timeoutMs}ms)...`);
        script.runInContext(context, { timeout: timeoutMs / 2, displayErrors: true });
        executionResult = await Promise.race([
            sandbox.__resultPromise__,
            new Promise((_, reject) => setTimeout(() => reject(new Error('Async operation timed out')), timeoutMs))
        ]);
        console.error(`[EVAL Logic] Sandboxed code finished successfully.`);
    } catch (error: any) {
        console.error("[EVAL Logic] Error executing sandboxed code:", error);
        executionError = error; // Store error to include in final output
    }

    // Compile final output structure including result/logs/errors
    const finalOutput: z.infer<typeof EvalRecordOutputSchema> = {
        result: executionResult, // Might be undefined if error occurred
        logs: logs,
        errors: errors
    };

    // Add execution error message if one occurred
    if (executionError) {
        let errorMessage: string;
        if (executionError.message.includes('timed out')) errorMessage = `Code execution timed out after ${timeoutMs / 1000} seconds.`;
        else if (executionError instanceof SyntaxError) errorMessage = `Syntax error in provided code: ${executionError.message}`;
        else errorMessage = `Error during code execution: ${executionError.message}`;
        finalOutput.errors.push(`Execution Error: ${errorMessage}`);
         finalOutput.result = undefined; // Ensure result is undefined on execution error
    }

     // Check JSON serializability before final truncation check
     try {
         JSON.stringify(finalOutput.result);
     } catch (stringifyError: any) {
         console.error("[EVAL Logic] Result is not JSON serializable:", stringifyError);
         finalOutput.errors.push(`Execution Error: Result is not JSON-serializable: ${stringifyError.message}.`);
         finalOutput.result = undefined; // Set result to undefined as it cannot be sent
     }

    // Truncate the final compiled output if needed
    const finalData = truncateIfNeeded(finalOutput, MAX_EVAL_JSON_LENGTH, 'eval');
    return JSON.stringify(finalData, null, 2);
}